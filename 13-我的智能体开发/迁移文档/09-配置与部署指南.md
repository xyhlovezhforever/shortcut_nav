# 09-配置与部署指南

## 概述

本文档详细描述任务编排服务的配置系统、环境区分、依赖服务和部署流程。

---

## 配置文件结构

### 配置文件命名

```
config.toml       # 基础配置（可选）
config.dev.toml   # 开发环境配置
config.prod.toml  # 生产环境配置
config.local.toml # 本地配置
```

### 配置加载优先级

```rust
// src/config/mod.rs

impl AppConfig {
    pub fn load() -> Result<Self, config::ConfigError> {
        let env = std::env::var("APP_ENV").unwrap_or_else(|_| "dev".to_string());

        let builder = config::Config::builder()
            // 1. 从默认配置文件开始（可选）
            .add_source(config::File::with_name("config").required(false))
            // 2. 添加环境特定配置文件
            .add_source(config::File::with_name(&format!("config.{}", env)).required(false))
            // 3. 添加环境变量 (APP_前缀)
            .add_source(config::Environment::with_prefix("APP").separator("_"));

        builder.build()?.try_deserialize()
    }
}
```

**优先级从低到高**：
1. 默认值（代码中的 Default 实现）
2. `config.toml`（基础配置）
3. `config.{env}.toml`（环境特定配置）
4. 环境变量（`APP_` 前缀）

---

## 配置结构定义

### AppConfig - 主配置结构

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct AppConfig {
    pub server: ServerConfig,              // 服务器配置
    pub llm: LlmConfig,                    // LLM 配置
    pub tool_service: ToolServiceConfig,  // Tool Service 配置
    pub orchestrator: OrchestratorConfig, // 编排器配置
    pub logging: LoggingConfig,           // 日志配置
    pub consul: ConsulServiceConfig,      // Consul 配置
    pub database_service: DatabaseServiceConfig, // 数据库配置
    pub kafka_service: KafkaServiceConfig,       // Kafka 配置
    pub reflection: ReflectionConfig,     // 反思配置
    pub response: ResponseConfig,         // 响应消息配置
    pub debug: DebugConfig,               // 调试配置
}
```

---

## 详细配置说明

### 1. 服务器配置 (ServerConfig)

```toml
[server]
host = "0.0.0.0"           # 监听地址
port = 8084                # 监听端口
request_timeout_secs = 60  # 请求超时时间（秒）
max_connections = 1000     # 最大连接数
```

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct ServerConfig {
    pub host: String,
    pub port: u16,
    pub request_timeout_secs: u64,
    pub max_connections: usize,
}

impl Default for ServerConfig {
    fn default() -> Self {
        Self {
            host: "127.0.0.1".to_string(),
            port: 8080,
            request_timeout_secs: 60,
            max_connections: 1000,
        }
    }
}
```

---

### 2. LLM 配置 (LlmConfig)

```toml
[llm]
service_name = "common-service"              # 服务名称（Consul服务发现）
endpoint = "http://common-service:9000"      # API 端点
protocol = "grpc"                            # 协议类型: "http" 或 "grpc"
api_key = ""                                 # API Key（可选）
default_model = "qwen3-max"                  # 默认模型
timeout_secs = 120                           # 请求超时时间（秒）
max_retries = 3                              # 最大重试次数
temperature = 0.7                            # 温度参数
top_p = 0.9                                  # Top P 参数
enable_streaming = true                      # 是否启用流式返回
max_streaming_indicators = 5                 # 流式进度指示器最大循环数
```

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct LlmConfig {
    pub service_name: Option<String>,
    pub endpoint: String,
    pub fallback_endpoint: Option<String>,   // 备用端点
    pub api_key: Option<String>,
    pub default_model: String,
    pub timeout_secs: u64,
    pub max_retries: u32,
    pub temperature: f32,
    pub top_p: f32,
    pub protocol: String,
    pub enable_streaming: bool,
    pub max_streaming_indicators: usize,
}
```

---

### 3. Tool Service 配置 (ToolServiceConfig)

```toml
[tool_service]
service_name = "tool-service"            # 服务名称
endpoint = "http://tool-service:8100"    # gRPC 端点
protocol = "grpc"                        # 协议类型
connect_timeout_secs = 5                 # 连接超时时间（秒）
timeout_secs = 7200                      # 请求超时时间（秒）
max_retries = 3                          # 最大重试次数
```

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct ToolServiceConfig {
    pub service_name: Option<String>,
    pub endpoint: String,
    pub fallback_endpoint: Option<String>,
    pub connect_timeout_secs: u64,
    pub timeout_secs: u64,
    pub max_retries: u32,
    pub protocol: String,
}
```

---

### 4. 编排器配置 (OrchestratorConfig)

```toml
[orchestrator]
# 反思与规划
max_reflection_rounds = 5           # 最大反思轮次
task_timeout_secs = 3600            # 任务执行超时时间（秒）
enable_auto_reflection = true       # 是否启用自动反思
success_threshold = 80.0            # 成功评分阈值（0-100）
max_concurrent_tasks = 1000         # 最大并发任务数

# 两阶段规划
enable_two_stage_planning = true    # 是否启用两阶段规划
two_stage_tool_threshold = 10       # 启用两阶段规划的最小工具数量阈值
enable_builtin_workflows = true     # 是否启用内置工作流
tool_selection_threshold = 85.0     # 工具筛选相似度阈值（0-100）

# 并行执行
enable_parallel_execution = true    # 是否启用并行执行
parallel_max_concurrent = 8         # 并行执行的最大并发数
parallel_min_steps = 1              # 并行执行的最小步骤数阈值
```

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct OrchestratorConfig {
    pub max_reflection_rounds: u32,
    pub task_timeout_secs: u64,
    pub enable_auto_reflection: bool,
    pub success_threshold: f32,
    pub max_concurrent_tasks: usize,
    pub enable_two_stage_planning: bool,
    pub two_stage_tool_threshold: usize,
    pub enable_builtin_workflows: bool,
    pub tool_selection_threshold: f32,
    pub enable_parallel_execution: bool,
    pub parallel_max_concurrent: usize,
    pub parallel_min_steps: usize,
}
```

**并行执行配置说明**：

| 配置项 | 默认值 | 说明 |
|--------|--------|------|
| `enable_parallel_execution` | true | 是否启用步骤间并行执行 |
| `parallel_max_concurrent` | 8 | 最大并发步骤数（信号量上限） |
| `parallel_min_steps` | 2 | 启用并行的最小步骤数阈值 |

**性能调优建议**：
- IO密集型任务: `parallel_max_concurrent = CPU核心数 * 2~4`
- CPU密集型任务: `parallel_max_concurrent = CPU核心数`
- 混合型任务: `parallel_max_concurrent = CPU核心数 * 2`

---

### 5. 反思配置 (ReflectionConfig)

```toml
[reflection]
enable_step_level_reflection = true   # 是否启用步骤级反思
max_consecutive_failures = 3          # 最大连续失败次数
max_replanning_attempts = 1           # 最大重新规划次数
```

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct ReflectionConfig {
    pub max_step_retries: usize,              // 单个步骤最大重试次数（默认3）
    pub max_task_replanning_attempts: usize,  // 任务级别最大重新规划次数（默认1）
    pub max_consecutive_failures: usize,      // 最大连续失败次数（兼容字段）
    pub max_replanning_attempts: usize,       // 最大重新规划次数（兼容字段）
    pub enable_step_level_reflection: bool,   // 是否启用步骤级反思
}
```

---

### 6. 日志配置 (LoggingConfig)

```toml
[logging]
level = "info"                                    # 日志级别: trace, debug, info, warn, error
console = true                                    # 是否输出到控制台
file = false                                      # 是否输出到文件
file_path = "logs/task-orchestration-service.log" # 日志文件路径
format = "text"                                   # 日志格式: text, json
```

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct LoggingConfig {
    pub level: String,
    pub console: bool,
    pub file: bool,
    pub file_path: Option<String>,
    pub format: String,
}
```

---

### 7. Consul 配置 (ConsulServiceConfig)

```toml
[consul]
enabled = true                                    # 是否启用 Consul 服务注册
host = "192.168.0.141"                           # Consul 服务器地址
port = 8500                                       # Consul 服务器端口
service_name = "task-orchestration-service"       # 服务名称
service_host = "192.168.0.15"                    # 服务主机地址
service_port = 8084                              # 服务端口
health_check_interval = 10                       # 健康检查间隔（秒）
health_check_timeout = 5                         # 健康检查超时时间（秒）
health_check_url = "http://192.168.0.15:8084/health" # 健康检查URL
```

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct ConsulServiceConfig {
    pub enabled: bool,
    pub host: String,
    pub port: u16,
    pub service_name: String,
    pub service_host: String,
    pub service_port: u16,
    pub health_check_interval: u64,
    pub health_check_timeout: u64,
    pub health_check_url: String,
}
```

---

### 8. Kafka 配置 (KafkaServiceConfig)

```toml
[kafka_service]
enabled = true                          # 是否启用
brokers = ["192.168.0.141:9092"]       # Kafka brokers 地址列表
topic = "task-audit-log"               # 主题名称
compression = "none"                    # 压缩类型: none, snappy, gzip, lz4, zstd
connect_timeout_secs = 5               # 连接超时时间（秒）
timeout_secs = 60                      # 请求超时时间（秒）
max_retries = 3                        # 最大重试次数
```

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct KafkaServiceConfig {
    pub enabled: bool,
    pub brokers: Vec<String>,
    pub topic: String,
    pub compression: String,
    pub connect_timeout_secs: u64,
    pub timeout_secs: u64,
    pub max_retries: u32,
    pub protocol: Option<String>,  // 已废弃
}
```

---

### 9. 响应配置 (ResponseConfig)

```toml
[response]
mode = "user"   # 响应消息模式: developer 或 user
```

```rust
#[derive(Debug, Clone, Copy, Deserialize, Serialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum ResponseMode {
    Developer,  // 技术性、简洁的消息（适合开发调试）
    User,       // 人性化、友好的中文消息（适合最终用户）
}

#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct ResponseConfig {
    pub mode: ResponseMode,
}
```

---

### 10. 调试配置 (DebugConfig)

```toml
[debug]
save_debug_log = true                              # 是否将调试信息写入文件
debug_log_file = "test_log.txt"                   # 调试日志文件路径
save_context_engineering_event = true             # 是否将上下文工程事件写入文件
context_engineering_file = "context_engineering_events.txt" # 上下文工程事件文件路径
```

```rust
#[derive(Debug, Clone, Deserialize, Serialize)]
pub struct DebugConfig {
    pub save_debug_log: bool,
    pub debug_log_file: String,
    pub save_context_engineering_event: bool,
    pub context_engineering_file: String,
}
```

---

## 完整配置模板

### 开发环境配置 (config.dev.toml)

```toml
# 开发环境配置

[server]
host = "0.0.0.0"
port = 8084
request_timeout_secs = 60
max_connections = 1000

[llm]
service_name = "common-service"
endpoint = "http://common-service:9000"
protocol = "grpc"
api_key = ""
default_model = "qwen3-max"
timeout_secs = 120
max_retries = 3
temperature = 0.7
top_p = 0.9
enable_streaming = true
max_streaming_indicators = 5

[tool_service]
service_name = "tool-service"
endpoint = "http://tool-service:8100"
protocol = "grpc"
connect_timeout_secs = 5
timeout_secs = 7200
max_retries = 3

[database_service]
service_name = "database-service"
endpoint = "http://database-service:9001"
protocol = "http"
connect_timeout_secs = 5
timeout_secs = 60
max_retries = 3
connection_string = "postgresql://user:password@localhost:5432/mydb"
max_connections = 20

[kafka_service]
enabled = true
brokers = ["192.168.0.141:9092"]
topic = "task-audit-log"
compression = "none"
connect_timeout_secs = 5
timeout_secs = 60
max_retries = 3

[orchestrator]
max_reflection_rounds = 5
task_timeout_secs = 3600
enable_auto_reflection = true
success_threshold = 80.0
max_concurrent_tasks = 1000
enable_two_stage_planning = true
two_stage_tool_threshold = 10
enable_builtin_workflows = true
tool_selection_threshold = 85.0
enable_parallel_execution = true
parallel_max_concurrent = 8
parallel_min_steps = 1

[reflection]
enable_step_level_reflection = true
max_consecutive_failures = 3
max_replanning_attempts = 1

[logging]
level = "info"
console = true
file = false
file_path = "logs/task-orchestration-service.log"
format = "text"

[consul]
enabled = true
host = "192.168.0.141"
port = 8500
service_name = "task-orchestration-service"
service_host = "192.168.0.15"
service_port = 8084
health_check_interval = 10
health_check_timeout = 5
health_check_url = "http://192.168.0.15:8084/health"

[response]
mode = "user"

[debug]
save_debug_log = true
debug_log_file = "test_log.txt"
save_context_engineering_event = true
context_engineering_file = "context_engineering_events.txt"
```

### 生产环境配置 (config.prod.toml)

```toml
# 生产环境配置

[server]
host = "0.0.0.0"
port = 8084
request_timeout_secs = 60
max_connections = 1000

[llm]
service_name = "common-service"
endpoint = "http://common-service:9000"
protocol = "grpc"
default_model = "qwen-plus"
timeout_secs = 120
max_retries = 3
temperature = 0.7
top_p = 0.9

[tool_service]
service_name = "tool-service"
endpoint = "http://tool-service:8100"
protocol = "grpc"
connect_timeout_secs = 5
timeout_secs = 60
max_retries = 3

[orchestrator]
max_reflection_rounds = 5
task_timeout_secs = 300
enable_auto_reflection = true
success_threshold = 80.0
max_concurrent_tasks = 10
enable_two_stage_planning = true
tool_selection_threshold = 90.0

[logging]
level = "info"
console = true
file = false

[consul]
enabled = true
host = "192.168.0.141"
port = 8500
service_name = "task-orchestration-service"

[response]
mode = "user"

[debug]
save_debug_log = false
```

---

## 环境变量

### 支持的环境变量

| 环境变量 | 说明 | 示例 |
|----------|------|------|
| `APP_ENV` | 运行环境 | `dev`, `prod`, `local` |
| `APP_SERVER_HOST` | 服务器监听地址 | `0.0.0.0` |
| `APP_SERVER_PORT` | 服务器端口 | `8084` |
| `APP_LLM_ENDPOINT` | LLM API 端点 | `http://localhost:9000` |
| `APP_LLM_DEFAULT_MODEL` | 默认LLM模型 | `qwen-plus` |
| `APP_CONSUL_ENABLED` | 是否启用Consul | `true`, `false` |
| `APP_LOGGING_LEVEL` | 日志级别 | `debug`, `info`, `warn` |

### 环境变量命名规则

环境变量使用 `APP_` 前缀，配置层级使用 `_` 分隔：

```bash
# 设置服务器端口
export APP_SERVER_PORT=8084

# 设置LLM端点
export APP_LLM_ENDPOINT=http://localhost:9000

# 设置日志级别
export APP_LOGGING_LEVEL=debug
```

---

## 依赖服务

### 必需服务

| 服务 | 用途 | 默认端口 |
|------|------|----------|
| LLM Service | 大语言模型推理 | 9000 (gRPC) |
| Tool Service | 工具执行 | 8100 (gRPC) |

### 可选服务

| 服务 | 用途 | 默认端口 |
|------|------|----------|
| Consul | 服务注册与发现 | 8500 |
| Kafka | 审计日志 | 9092 |
| Database Service | 数据存储 | 9001 |

---

## 构建与编译

### 依赖安装

```bash
# Rust 工具链
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# 安装 protobuf 编译器 (Windows)
choco install protoc

# 安装 protobuf 编译器 (Linux)
apt-get install protobuf-compiler

# 安装 protobuf 编译器 (MacOS)
brew install protobuf
```

### 编译命令

```bash
# 开发构建
cargo build

# 发布构建
cargo build --release

# 启用 Kafka 支持的构建
cargo build --release --features kafka
```

### Cargo.toml 特性配置

```toml
[features]
default = []
kafka = ["rdkafka"]

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
strip = true
```

---

## 运行方式

### 直接运行

```bash
# 开发环境
APP_ENV=dev cargo run

# 生产环境
APP_ENV=prod cargo run --release

# 指定配置文件
APP_ENV=local cargo run
```

### 可执行文件

```bash
# HTTP 服务
./target/release/task-orchestration-service

# gRPC 服务
./target/release/task-orchestration-service-grpc
```

### 示例程序

```bash
# 运行测试用例
cargo run --example universal_case_test
cargo run --example digital_twin_test
cargo run --example concurrent_batch_test
cargo run --example multi_turn_conversation_test
```

---

## Docker 部署

### Dockerfile 模板

```dockerfile
# 构建阶段
FROM rust:1.75 as builder

WORKDIR /app

# 安装 protobuf
RUN apt-get update && apt-get install -y protobuf-compiler

# 复制源码
COPY . .

# 构建
RUN cargo build --release --features kafka

# 运行阶段
FROM debian:bookworm-slim

WORKDIR /app

# 安装运行时依赖
RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    && rm -rf /var/lib/apt/lists/*

# 复制二进制文件
COPY --from=builder /app/target/release/task-orchestration-service .
COPY --from=builder /app/config.prod.toml ./config.prod.toml

# 设置环境变量
ENV APP_ENV=prod
ENV RUST_LOG=info

# 暴露端口
EXPOSE 8084

# 启动命令
CMD ["./task-orchestration-service"]
```

### docker-compose.yml 模板

```yaml
version: '3.8'

services:
  task-orchestration-service:
    build: .
    ports:
      - "8084:8084"
    environment:
      - APP_ENV=prod
      - APP_SERVER_HOST=0.0.0.0
      - APP_SERVER_PORT=8084
      - APP_CONSUL_ENABLED=true
      - APP_CONSUL_HOST=consul
    depends_on:
      - consul
      - llm-service
      - tool-service
    networks:
      - orchestration-network

  consul:
    image: consul:latest
    ports:
      - "8500:8500"
    networks:
      - orchestration-network

  llm-service:
    image: your-llm-service:latest
    ports:
      - "9000:9000"
    networks:
      - orchestration-network

  tool-service:
    image: your-tool-service:latest
    ports:
      - "8100:8100"
    networks:
      - orchestration-network

networks:
  orchestration-network:
    driver: bridge
```

---

## 健康检查

### HTTP 健康检查端点

```
GET /health
```

响应：
```json
{
    "status": "healthy",
    "version": "0.1.0",
    "timestamp": "2024-01-15T10:30:00Z"
}
```

### Consul 健康检查配置

```toml
[consul]
health_check_interval = 10    # 每10秒检查一次
health_check_timeout = 5      # 5秒超时
health_check_url = "http://192.168.0.15:8084/health"
```

---

## 日志与监控

### 日志输出格式

**Text 格式**：
```
2024-01-15T10:30:00.123Z  INFO task_orchestration_service: 任务执行开始 task_id="abc123"
```

**JSON 格式**：
```json
{
    "timestamp": "2024-01-15T10:30:00.123Z",
    "level": "INFO",
    "target": "task_orchestration_service",
    "message": "任务执行开始",
    "task_id": "abc123"
}
```

### Kafka 审计日志

审计日志发送到配置的 Kafka topic，包含：
- 任务提交事件
- 任务完成事件
- 任务取消事件
- 步骤执行事件

---

## 故障排查

### 常见问题

1. **服务无法启动**
   - 检查配置文件格式是否正确
   - 检查端口是否被占用
   - 检查依赖服务是否可达

2. **Consul 注册失败**
   - 检查 Consul 服务是否运行
   - 检查网络连接
   - 检查健康检查 URL 是否正确

3. **LLM 调用超时**
   - 增加 `llm.timeout_secs` 配置
   - 检查 LLM 服务负载
   - 检查网络延迟

4. **工具执行失败**
   - 检查 Tool Service 连接
   - 查看调试日志 (`debug.save_debug_log = true`)
   - 检查工具参数格式

### 调试技巧

```toml
# 启用调试日志
[logging]
level = "debug"

[debug]
save_debug_log = true
debug_log_file = "debug_log.txt"
save_context_engineering_event = true
```

---

## 关键文件索引

| 文件 | 说明 |
|------|------|
| `src/config/mod.rs` | 配置结构定义和加载逻辑 |
| `config.dev.toml` | 开发环境配置 |
| `config.prod.toml` | 生产环境配置 |
| `src/main.rs` | HTTP 服务入口 |
| `src/main_grpc.rs` | gRPC 服务入口 |
| `Cargo.toml` | 项目依赖和构建配置 |
